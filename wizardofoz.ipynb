{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8646530,
          "sourceType": "datasetVersion",
          "datasetId": 5178760
        }
      ],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "wizardofoz",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'wizard-of-ozz:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5178760%2F8646530%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240612%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240612T080738Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D87ff890c8fa2bf989b00aec13a1d91334b0a04cc75f010e079c6351a487065b699d6f769e5a8acbdf1000ba94a7e91af9b6cdf74b061e2ecfc1b2241a45d369763f92aec13a752ecea65546edc5fac56e8957abf0223f77e5743511f0d9698fe4267719452f0fb0b15a0b292b709dec1f70609216c61d50d4b49dd835d7754739cffda63380e17e4eb3c39ead4bd30f0deb7c90d433483e3bea9dcfc10c3f3e7b23327eed7c9a6a553da150cba62826684fd257848268fca0e8c7627eda5b37d29a53c14a7f90d0a42b762436b64a68bb3202664f4823011c1c3d6d38347446f1e69a46491dbe2bbf988e08e42b8d0b506895655c26f1af4e64108767072d7e6'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "xLK6W6hffO2n"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "YF0jEnNbfO2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-09T08:24:00.040529Z",
          "iopub.execute_input": "2024-06-09T08:24:00.041252Z",
          "iopub.status.idle": "2024-06-09T08:24:00.04847Z",
          "shell.execute_reply.started": "2024-06-09T08:24:00.041216Z",
          "shell.execute_reply": "2024-06-09T08:24:00.047387Z"
        },
        "trusted": true,
        "id": "3YEARi_bfO2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/kaggle/input/wizard-of-ozz/wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "print(len(text))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-10T05:33:08.23053Z",
          "iopub.execute_input": "2024-06-10T05:33:08.231036Z",
          "iopub.status.idle": "2024-06-10T05:33:08.257768Z",
          "shell.execute_reply.started": "2024-06-10T05:33:08.230999Z",
          "shell.execute_reply": "2024-06-10T05:33:08.256194Z"
        },
        "trusted": true,
        "id": "JvtNZbrifO2q",
        "outputId": "d58a51a2-ee9f-4f07-e15f-14606de9bb17"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "232287\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:200])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-10T04:36:29.359444Z",
          "iopub.execute_input": "2024-06-10T04:36:29.359923Z",
          "iopub.status.idle": "2024-06-10T04:36:29.366604Z",
          "shell.execute_reply.started": "2024-06-10T04:36:29.359888Z",
          "shell.execute_reply": "2024-06-10T04:36:29.365341Z"
        },
        "trusted": true,
        "id": "c3preZYTfO2r",
        "outputId": "2c7acbaf-5186-466c-eee3-0dafbfb2962f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "ï»¿DOROTHY AND THE WIZARD IN OZ\n\nBY\n\nL. FRANK BAUM\n\nAUTHOR OF THE WIZARD OF OZ, THE LAND OF OZ, OZMA OF OZ, ETC.\n\nILLUSTRATED BY JOHN R. NEILL\n\nBOOKS OF WONDER WILLIAM MORROW & CO., INC. NEW YORK\n\n\n[Ill\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(set(text))\n",
        "print(chars)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-10T04:37:08.605388Z",
          "iopub.execute_input": "2024-06-10T04:37:08.605817Z",
          "iopub.status.idle": "2024-06-10T04:37:08.616634Z",
          "shell.execute_reply.started": "2024-06-10T04:37:08.605785Z",
          "shell.execute_reply": "2024-06-10T04:37:08.615284Z"
        },
        "trusted": true,
        "id": "UKJ_ZytVfO2r",
        "outputId": "1270a087-d9b7-49ed-97ae-8fb2eece9a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(chars))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-10T04:37:58.141044Z",
          "iopub.execute_input": "2024-06-10T04:37:58.141485Z",
          "iopub.status.idle": "2024-06-10T04:37:58.147891Z",
          "shell.execute_reply.started": "2024-06-10T04:37:58.141452Z",
          "shell.execute_reply": "2024-06-10T04:37:58.146542Z"
        },
        "trusted": true,
        "id": "zbQ2sOSufO2r",
        "outputId": "d1d5b10a-00e1-4ff8-d8b4-5143988ec75d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "81\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#character level tokenizer\n",
        "string_to_int = { ch:i for i, ch in enumerate(chars)}\n",
        "int_to_string = {i:ch for i, ch in enumerate(chars)}\n",
        "encode = lambda s: [string_to_int[c] for c in s]\n",
        "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
        "\n",
        "encoded_hello = encode(\"hello\")\n",
        "decoded_hello =  decode(encoded_hello)\n",
        "print(decoded_hello)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-10T04:42:03.397548Z",
          "iopub.execute_input": "2024-06-10T04:42:03.398905Z",
          "iopub.status.idle": "2024-06-10T04:42:03.407447Z",
          "shell.execute_reply.started": "2024-06-10T04:42:03.39886Z",
          "shell.execute_reply": "2024-06-10T04:42:03.405852Z"
        },
        "trusted": true,
        "id": "tIzOL2dyfO2r",
        "outputId": "fc124ea0-5535-4326-ff8c-b88988f50a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "hello\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-10T06:32:33.806844Z",
          "iopub.execute_input": "2024-06-10T06:32:33.80725Z",
          "iopub.status.idle": "2024-06-10T06:32:35.839786Z",
          "shell.execute_reply.started": "2024-06-10T06:32:33.80722Z",
          "shell.execute_reply": "2024-06-10T06:32:35.838071Z"
        },
        "trusted": true,
        "id": "MzWlpcYrfO2s",
        "outputId": "c13d7744-4209-41f4-8c2d-5baf0e661a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mencode\u001b[49m(text), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[:\u001b[38;5;241m100\u001b[39m])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'encode' is not defined"
          ],
          "ename": "NameError",
          "evalue": "name 'encode' is not defined",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.8*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-10T05:33:30.52905Z",
          "iopub.execute_input": "2024-06-10T05:33:30.529437Z",
          "iopub.status.idle": "2024-06-10T05:33:30.535545Z",
          "shell.execute_reply.started": "2024-06-10T05:33:30.529405Z",
          "shell.execute_reply": "2024-06-10T05:33:30.53438Z"
        },
        "trusted": true,
        "id": "AHGxFRXHfO2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print('when input is', context, 'target is', target)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-10T05:34:25.415319Z",
          "iopub.execute_input": "2024-06-10T05:34:25.415849Z",
          "iopub.status.idle": "2024-06-10T05:34:25.429791Z",
          "shell.execute_reply.started": "2024-06-10T05:34:25.415811Z",
          "shell.execute_reply": "2024-06-10T05:34:25.427629Z"
        },
        "trusted": true,
        "id": "_UZRBW5JfO2s",
        "outputId": "0f976f53-305c-4c3f-9ebd-c8aa41e39642"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "when input is tensor([80]) target is tensor(28)\nwhen input is tensor([80, 28]) target is tensor(39)\nwhen input is tensor([80, 28, 39]) target is tensor(42)\nwhen input is tensor([80, 28, 39, 42]) target is tensor(39)\nwhen input is tensor([80, 28, 39, 42, 39]) target is tensor(44)\nwhen input is tensor([80, 28, 39, 42, 39, 44]) target is tensor(32)\nwhen input is tensor([80, 28, 39, 42, 39, 44, 32]) target is tensor(49)\nwhen input is tensor([80, 28, 39, 42, 39, 44, 32, 49]) target is tensor(1)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>NEW</h1>"
      ],
      "metadata": {
        "id": "8WvAe2CUfO2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "block_size = 8\n",
        "batch_size = 4\n",
        "max_iters = 1000\n",
        "learning_rate= 3e-4\n",
        "eval_iters = 250\n",
        "dropout = 0.2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-12T03:35:17.601252Z",
          "iopub.execute_input": "2024-06-12T03:35:17.601917Z",
          "iopub.status.idle": "2024-06-12T03:35:17.615266Z",
          "shell.execute_reply.started": "2024-06-12T03:35:17.601872Z",
          "shell.execute_reply": "2024-06-12T03:35:17.613943Z"
        },
        "trusted": true,
        "id": "KaFcv3Y3fO2t",
        "outputId": "891b5d3e-2c08-4eed-9548-4709f5929b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "cpu\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/kaggle/input/wizard-of-ozz/wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "# print(len(text))\n",
        "chars = sorted(set(text))\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-12T03:35:19.615012Z",
          "iopub.execute_input": "2024-06-12T03:35:19.615497Z",
          "iopub.status.idle": "2024-06-12T03:35:19.638223Z",
          "shell.execute_reply.started": "2024-06-12T03:35:19.615459Z",
          "shell.execute_reply": "2024-06-12T03:35:19.637031Z"
        },
        "trusted": true,
        "id": "GqX8SddufO2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#character level tokenizer\n",
        "string_to_int = { ch:i for i, ch in enumerate(chars)}\n",
        "int_to_string = {i:ch for i, ch in enumerate(chars)}\n",
        "encode = lambda s: [string_to_int[c] for c in s]\n",
        "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-12T03:35:23.17266Z",
          "iopub.execute_input": "2024-06-12T03:35:23.173372Z",
          "iopub.status.idle": "2024-06-12T03:35:23.23932Z",
          "shell.execute_reply.started": "2024-06-12T03:35:23.173339Z",
          "shell.execute_reply": "2024-06-12T03:35:23.23831Z"
        },
        "trusted": true,
        "id": "eJvOKjE7fO2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.8*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "#     print(ix)\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "x,y = get_batch('train')\n",
        "print('inputs:')\n",
        "print(x)\n",
        "print('targets:')\n",
        "print(y)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-12T03:52:20.390996Z",
          "iopub.execute_input": "2024-06-12T03:52:20.391415Z",
          "iopub.status.idle": "2024-06-12T03:52:20.40294Z",
          "shell.execute_reply.started": "2024-06-12T03:52:20.391383Z",
          "shell.execute_reply": "2024-06-12T03:52:20.401646Z"
        },
        "trusted": true,
        "id": "o6SbrFz5fO2u",
        "outputId": "75321dce-d3f1-4458-c807-02756a734009"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "inputs:\ntensor([[ 1, 66, 54, 67,  1, 60, 54, 75],\n        [61, 58,  1, 72, 73, 71, 54, 67],\n        [ 1, 56, 68, 67, 72, 73, 71, 74],\n        [ 1, 76, 68, 74, 65, 57,  1, 57]])\ntargets:\ntensor([[66, 54, 67,  1, 60, 54, 75, 58],\n        [58,  1, 72, 73, 71, 54, 67, 60],\n        [56, 68, 67, 72, 73, 71, 74, 56],\n        [76, 68, 74, 65, 57,  1, 57, 68]])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "tSAPAMfafO2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print('when input is', context, 'target is', target)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-12T03:52:23.014699Z",
          "iopub.execute_input": "2024-06-12T03:52:23.01519Z",
          "iopub.status.idle": "2024-06-12T03:52:23.025038Z",
          "shell.execute_reply.started": "2024-06-12T03:52:23.015147Z",
          "shell.execute_reply": "2024-06-12T03:52:23.023711Z"
        },
        "trusted": true,
        "id": "OFtdfUh5fO2u",
        "outputId": "9903428a-ec3a-407e-ec28-5c1a4f30ec02"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "when input is tensor([80]) target is tensor(28)\nwhen input is tensor([80, 28]) target is tensor(39)\nwhen input is tensor([80, 28, 39]) target is tensor(42)\nwhen input is tensor([80, 28, 39, 42]) target is tensor(39)\nwhen input is tensor([80, 28, 39, 42, 39]) target is tensor(44)\nwhen input is tensor([80, 28, 39, 42, 39, 44]) target is tensor(32)\nwhen input is tensor([80, 28, 39, 42, 39, 44, 32]) target is tensor(49)\nwhen input is tensor([80, 28, 39, 42, 39, 44, 32, 49]) target is tensor(1)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, index, targets=None):\n",
        "        logits = self.token_embedding_table(index)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, index, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, loss = self.forward(index)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            index_next = torch.multinomial(probs, num_samples=1)\n",
        "            index = torch.cat((index, index_next), dim=1)\n",
        "        return index\n",
        "\n",
        "model = BigramLanguageModel(vocab_size)\n",
        "m = model.to(device)\n",
        "\n",
        "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
        "print(generated_chars)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-12T03:52:25.161388Z",
          "iopub.execute_input": "2024-06-12T03:52:25.16218Z",
          "iopub.status.idle": "2024-06-12T03:52:25.236121Z",
          "shell.execute_reply.started": "2024-06-12T03:52:25.162142Z",
          "shell.execute_reply": "2024-06-12T03:52:25.235068Z"
        },
        "trusted": true,
        "id": "031uinUBfO2u",
        "outputId": "a13f2db9-5f8e-43d9-b36c-47fd728f2c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\nVh\nc2fwRu!dZrofY)0MV[_WFHT ï»¿*5l*2h&wZvDmP3V?)8tS;vWNB]e20vï»¿]i:-'K 1ï»¿JAeEa9;BX3*l60p\"SUde3gI0\"GSsV?x-K JxW*ZBkQs:P.W&uO;(qYuTsi-e2Gj!9.0S3g4Zw'qB)64el0GjeojtM.bQ;09Q;NOBZly*)3K)yVd5.wL_a3x(c\"xKCS;7[dwjtuO-URP3VRw5FU,k3-ASfO] JNsxFd1NeQ&ZSj['J-sL:PjEv(YswUDB:hv.0;Z1xkCA5cI8AS]alD\"ym2;iBhYF!.ISaHP,Bz)R\neAq;7fR9Mi8s?Og&uPRQ&xCKiA5T)GS]bQ7nl7\"?6X2CxJ]H:ofq(\nH00AJIGdT.(g*HS6]L0[]:yLo)Tb?\n\"xn7HOAXdw!7[!l_7*oi ï»¿nJ&cI;04,e_5Zï»¿dRw;oMXFVTjVa!XQi48-[4yuQT.2_FI[-BJxBV6c2- )*!i(oBC9D?p-I8(vunVK0pCYo)sHSS3!).q\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_iters == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step: {iter}, train loss: {losses['train']:.4f}, val loss: {losses['val']: .4f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    logits, loss = model.forward(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(loss.item())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-12T03:52:28.160934Z",
          "iopub.execute_input": "2024-06-12T03:52:28.162068Z",
          "iopub.status.idle": "2024-06-12T03:52:35.38398Z",
          "shell.execute_reply.started": "2024-06-12T03:52:28.162026Z",
          "shell.execute_reply": "2024-06-12T03:52:35.382931Z"
        },
        "trusted": true,
        "id": "4GZCSPYsfO2u",
        "outputId": "0165ddc7-5782-4d5d-b4bb-1fab48250ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "3.354724407196045\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
        "print(generated_chars)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-12T03:53:16.89018Z",
          "iopub.execute_input": "2024-06-12T03:53:16.890546Z",
          "iopub.status.idle": "2024-06-12T03:53:16.956976Z",
          "shell.execute_reply.started": "2024-06-12T03:53:16.890519Z",
          "shell.execute_reply": "2024-06-12T03:53:16.955683Z"
        },
        "trusted": true,
        "id": "h7Vi5USefO2u",
        "outputId": "2e51c301-5e8d-4cb3-a8b1-ec539d131097"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\ni\"U20un s:5d,Gm3x:BnwR&ly_.9oBCl6]uefpex\"7,xyj6pJivueAI in xA\"5ry)tsp*qu&7u,DYlY,haXM ï»¿ghifngu. Zï»¿NW*(v,1idmI64e.an tsi:\nsnintag9NuroZreNt,[48:at\nU;SqZ0caunothfC64Pi\nxYy\nUhodettou a9PBppRqRFppywUdeo70Da3Q9DW*FVJ:Az[tSH0Ad t q9DC\nld R'l wnv5le tN8s t d,yEK4aig.n?CRJzicU,w&qTggutidh4IApoI6ALgbQg*TUdiraBb,hidmYo\"]Hxkn,dy,,JxOndo\nZu:A6)te t tyto8Q.\nw n?Ctï»¿TW,T_a9ghad OshoriltaXi_.KBy,halsToeqEUq!71W&ORrcYU6Wu,9N\nw\"\nly.\nw7t()*TJa3LHw&\"_lewa j])s JARARExJikBR&qTï»¿ulrhP1d ntqH5T)s\nlv&]VVN1&L_)H50'EWTM  \n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C0HPUt66fO2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AsXV3NsEfO2v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}